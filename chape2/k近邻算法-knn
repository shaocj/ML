#2018.3.22

mport numpy as np
import operator as op

def createDateSet():
    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])
    labels = ['A','A','B','B']
    return group, labels
def classify(inX,dataSet,labels,k):#inX是你要输入的要分类的“坐标”，dataSet是上面createDataSet的array，
就是已经有的，分类过的坐标，label是相应分类的标签，k是KNN，k近邻里面的k
    dataSetSize = dataSet.shape[0]#dataSetSize是sataSet的行数，用上面的举例就是4行  

    diffMat = np.tile(inX,(dataSetSize,1))-dataSet #前面用tile，把一行inX变成4行一模一样的（tile有重复的功能，
    ataSetSize是重复4遍，后面的1保证重复完了是4行，而不是一行里有四个一样的），然后再减去dataSet，是为了求两点的距离，先要坐标相减，
    这个就是坐标相减  

    sqDiffMat = diffMat**2#上一行得到了坐标相减，然后这里要(x1-x2)^2，要求乘方  
    sqDistance = sqDiffMat.sum(axis=1)
    distance = sqDistance**0.5
    sortedDistIndicies = distance.argsort()#argsort是排序，将元素按照由小到大的顺序返回下标，比如([3,1,2]),它返回的就是([1,2,0])  
    classCount = {}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1#get是取字典里的元素，如果之前这个voteIlabel是有的，
        那么就返回字典里这个voteIlabel里的值，如果没有就返回0（后面写的），这行代码的意思就是算离目标点距离最近的k个点的类别，这个点是哪个类别哪个类别就加1  
    #print(classCount)
    sortedClassCount = sorted(classCount.items(),key=op.itemgetter(1),reverse = True)
    #print(sortedClassCount)
    #print(classCount.items())
    #print(op.itemgetter(1))
    return sortedClassCount[0][0]
#收集数据：文本
#准备数据
def file2matrix(filename):
    love_dictionary = {'largeDoses': 3, 'smallDoses': 2, 'didntLike': 1}
    fr = open(filename)
    arrayOLines = fr.readlines()
    numberOfLines = len(arrayOLines)
    returnMat = np.zeros((numberOfLines,3))
    classLabelVector = []
    index = 0
    for line in arrayOLines:
        line = line.strip()
        listFromLine = line.split('\t')
        returnMat[index,:] = listFromLine[0:3]
        if (listFromLine[-1].isdigit()):
            classLabelVector.append(int(listFromLine[-1]))
        else:
            classLabelVector.append(love_dictionary.get(listFromLine[-1]))
        index += 1
    return returnMat,classLabelVector
    #分析数据：可视化
    #准备数据-归一化
    #在处理不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为0到1或者-1到1之间。
    newValue=(oldValue-min)/(max-min),autoNorm自动将数字特征值转化为0到1的区间
    #归一化特征值
    def autoNorm(dataSet):
    minVals = dataSet.min(0)
    maxVals = dataSet.max(0)
    ranges = maxVals - minVals
    normDataSet = np.zeros(np.shape(dataSet))
    m = np.shape(dataSet)[0]
    normDataSet = dataSet - np.tile(minVals,(m,1))
    normDataSet = normDataSet/np.tile(ranges,(m,1))
    return normDataSet,ranges,minVals
    
    #测试算法
    #使用错误率来检测分类器性能，定义一个计数器变量每次分类器错误的分类数据计数器加1，计数器结果处理数据点总数即是错误率，下列函数就是测试分类器效果
    def datingClassTest():
    hoRation = 0.10
    datingDataMat, datingLabels = file2matrix('datingTestSet.txt')
    normMat, ranges, minVals = autoNorm(datingDataMat)
    m = np.shape(normMat)[0]
    numTestVecs = int(m*hoRation)
    errorCount = 0.0
    for i in range(numTestVecs):
        classifierResult = classify(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)
        print("the classifier came back with:%d,the real answer is : %d"% (classifierResult,datingLabels[i]))
        if (classifierResult != datingLabels[i]):errorCount += 1.0
    print("the total error rate is : %f "%(errorCount/float(numTestVecs)))
    #使用算法
    def classifyPerson():
    resultList = ['not at all', 'in small doses', 'in large doses']
    percentTats = float(input(\
                                  "percentage of time spent playing video games?"))
    ffMiles = float(input("frequent flier miles earned per year?"))
    iceCream = float(input("liters of ice cream consumed per year?"))
    datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')
    normMat, ranges, minVals = autoNorm(datingDataMat)
    inArr = np.array([ffMiles, percentTats, iceCream, ])
    classifierResult = classify0((inArr - \
                                  minVals)/ranges, normMat, datingLabels, 3)
    print("You will probably like this person: %s" % resultList[classifierResult - 1])
