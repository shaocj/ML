#2018.3.22

mport numpy as np
import operator as op

def createDateSet():
    group = np.array([[1.0,1.1],[1.0,1.0],[0,0],[0,0.1]])
    labels = ['A','A','B','B']
    return group, labels
def classify(inX,dataSet,labels,k):#inX是你要输入的要分类的“坐标”，dataSet是上面createDataSet的array，
就是已经有的，分类过的坐标，label是相应分类的标签，k是KNN，k近邻里面的k
    #距离计算
    dataSetSize = shape（dataSet）[0]#dataSetSize是sataSet的行数，用上面的举例就是4行  

    diffMat = np.tile(inX,(dataSetSize,1))-dataSet #前面用tile，把一行inX变成4行一模一样的（tile有重复的功能，
    ataSetSize是重复4遍，后面的1保证重复完了是4行，而不是一行里有四个一样的），然后再减去dataSet，是为了求两点的距离，先要坐标相减，
    这个就是坐标相减  

    sqDiffMat = diffMat**2#上一行得到了坐标相减，然后这里要(x1-x2)^2，要求乘方  
    sqDistance = sqDiffMat.sum(axis=1)
    distance = sqDistance**0.5
    sortedDistIndicies = distance.argsort()#argsort是排序，将元素按照由小到大的顺序返回下标，比如([3,1,2]),它返回的就是([1,2,0])  
    #选择距离最小的k个点
    classCount = {}
    for i in range(k):
        voteIlabel = labels[sortedDistIndicies[i]]
        classCount[voteIlabel] = classCount.get(voteIlabel,0)+1#get是取字典里的元素，如果之前这个voteIlabel是有的，
        那么就返回字典里这个voteIlabel里的值，如果没有就返回0（后面写的），这行代码的意思就是算离目标点距离最近的k
        个点的类别，这个点是哪个类别哪个类别就加1  
    #print(classCount)
    #排序
    sortedClassCount = sorted(classCount.items(),key=op.itemgetter(1),reverse = True)
    #sort 与 sorted 区别：sort 是应用在 list 上的方法，sorted 可以对所有可迭代的对象进行排序操作,key -- 主要是
    用来进行比较的元素，只有一个参数，具体的函数的参数就是取自于可迭代对象中，指定可迭代对象中的
    一个元素来进行排序,key的参数为一个函数或者lambda函数。operator模块提供的itemgetter函数用于获取对象的哪些维的数据，
    参数为一些序号.operator块提供的itemgetter函数用于获取对象的哪些维的数据，参数为一些序号。a = [1,2,3] b=operator.itemgetter(1)      //定义函数b，获取对象的第1个域的值
 那么b(a) 就是2，b=operator.itemgetter(1,0)  //定义函数b，获取对象的第1个域和第0个的值 b(a)就为(2, 1)，reverse
 -- 排序规则，reverse = True 降序 ， reverse = False 升序（默认）。
    #print(sortedClassCount)
    #print(classCount.items())
    #print(op.itemgetter(1))
    return sortedClassCount[0][0]
    
    
    
#收集数据：文本

#准备数据
def file2matrix(filename):
    #得到文件行数
    love_dictionary = {'largeDoses': 3, 'smallDoses': 2, 'didntLike': 1}
    fr = open(filename)
    arrayOLines = fr.readlines()
    numberOfLines = len(arrayOLines)
    ###
    关于readlines()方法：
    1、一次性读取整个文件。
    2、自动将文件内容分析成一个行的列表。
    关于readline()方法：
    1、readline()每次读取一行，比readlines()慢得多
    2、readline()返回的是一个字符串对象，保存当前行的内容
    关于read()方法：
     1、读取整个文件，将文件内容放到一个字符串变量中
     2、如果文件大于可用内存，不可能使用这种处理
    ####
    #创建3行3列的0矩阵
    returnMat = np.zeros((numberOfLines,3))
    #解析文件数据到列表
    classLabelVector = []
    index = 0
    for line in arrayOLines:
        line = line.strip()#返回移除字符串头尾指定的字符生成的新字符串
        listFromLine = line.split('\t')##Python split() 通过指定分隔符对字符串进行切片，如果参数 num 有指定值，
        则仅分隔 num 个子字符串###
        returnMat[index,:] = listFromLine[0:3]
        if (listFromLine[-1].isdigit()):
            classLabelVector.append(int(listFromLine[-1]))
        else:
            classLabelVector.append(love_dictionary.get(listFromLine[-1]))
        index += 1
    return returnMat,classLabelVector
    
#分析数据：可视化

    #准备数据-归一化
    #在处理不同取值范围的特征值时，我们通常采用的方法是将数值归一化，如将取值范围处理为0到1或者-1到1之间。
    newValue=(oldValue-min)/(max-min),autoNorm自动将数字特征值转化为0到1的区间
    #归一化特征值
    def autoNorm(dataSet):
        minVals = dataSet.min(0)#取出数据集中的最小值
        maxVals = dataSet.max(0)#取出数据集中的最大值
        ranges = maxVals - minVals
        normDataSet = np.zeros(np.shape(dataSet))#初始化一个矩阵，该矩阵和所给数据集维度相同用于存放归一化之后的数据
        m = np.shape(dataSet)[0]#取出数据集的行数
        normDataSet = dataSet - np.tile(minVals,(m,1))#这里tile()函数创建了一个以min_value为值的m行列向量，
        然后计算oldValue-min_value###
        normDataSet = normDataSet/np.tile(ranges,(m,1))#特征值相除得到归一化后的数值
        return normDataSet,ranges,minVals#返回归一化后的数据
    
    #测试算法
    #使用错误率来检测分类器性能，定义一个计数器变量每次分类器错误的分类数据计数器加1，计数器结果处理
    数据点总数即是错误率，下列函数就是测试分类器效果##
    def datingClassTest():
        hoRation = 0.10
        datingDataMat, datingLabels = file2matrix('datingTestSet.txt')
        normMat, ranges, minVals = autoNorm(datingDataMat)
        m = np.shape(normMat)[0]
        numTestVecs = int(m*hoRation)
        errorCount = 0.0
        for i in range(numTestVecs):
            classifierResult = classify(normMat[i,:],normMat[numTestVecs:m,:],datingLabels[numTestVecs:m],3)
             print("the classifier came back with:%d,the real answer is : %d"% (classifierResult,datingLabels[i]))
            if (classifierResult != datingLabels[i]):errorCount += 1.0
        print("the total error rate is : %f "%(errorCount/float(numTestVecs)))
    
    
    #使用算法
    def classifyPerson():
        resultList = ['not at all', 'in small doses', 'in large doses']
        percentTats = float(input(\
                                  "percentage of time spent playing video games?"))
         ffMiles = float(input("frequent flier miles earned per year?"))
        iceCream = float(input("liters of ice cream consumed per year?"))
        datingDataMat, datingLabels = file2matrix('datingTestSet2.txt')
        normMat, ranges, minVals = autoNorm(datingDataMat)
        inArr = np.array([ffMiles, percentTats, iceCream, ])
        classifierResult = classify0((inArr - \
                                  minVals)/ranges, normMat, datingLabels, 3)
        print("You will probably like this person: %s" % resultList[classifierResult - 1])
    
    
def img2vector(filename):
    returnVect = np.zeros((1,1024))
    fr = open(filename)
    for i in range(32):
        lineStr = fr.readline()
        for j in range(32):
            returnVect[0,32*i+j] = int(lineStr[j])
        return returnVect
