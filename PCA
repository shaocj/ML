https://www.cnblogs.com/tbiiann/p/6259459.html
http://blog.codinglabs.org/articles/pca-tutorial.html
https://blog.csdn.net/lanchunhui/article/details/53996070
    我们可以认为两者是线性相关的，即知道下单数，我们可以得到付款数，这里很明显这两个属性维度有冗余，去掉下单数，保留付款数，
明显能再保证原有数据分布和信息的情况下有效简化数据，对于后面的模型学习会缩短不少时间和空间开销。这就是降维，当然并不是
所有数据中都会有过于明显线性相关的属性维度，我们降维后最终的目标是各个属性维度之间线性无关。
*****PCA降维步骤原理******

首先既然要度量那些是否存在相关的属性，我们就要用到协方差，在博客相关分析中有介绍，这里不再赘述，协方差衡量的是2维属性
间的相关性，对于n个维度的属性，就需要协方差矩阵，其对角线为各维度的方差。

步骤：


                       设有m条n维数据。

                      1）将原始数据按列组成n行m列矩阵X

                      2）将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值

                      3）求出协方差矩阵

                      4）求出协方差矩阵的特征值及对应的特征向量r

                      5）将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P

                      6）即为降维到k维后的数据


