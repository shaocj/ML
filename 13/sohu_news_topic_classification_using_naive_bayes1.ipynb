{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#! /usr/bin/env python\n",
    "#coding=utf-8\n",
    "\n",
    "# Authors: Hanxiaoyang <hanxiaoyang.ml@gmail.com>\n",
    "# simple naive bayes classifier to classify sohu news topic\n",
    "# data can be downloaded in http://www.sogou.com/labs/dl/cs.html\n",
    "\n",
    "# 代码功能：简易朴素贝叶斯分类器，用于对搜狐新闻主题分类，数据可在http://www.sogou.com/labs/dl/cs.html下载(精简版)\n",
    "# 详细说明参见博客http://blog.csdn.net/han_xiaoyang/article/details/50629608\n",
    "# 作者：寒小阳<hanxiaoyang.ml@gmail.com>\n",
    "\n",
    "import sys, math, random, collections\n",
    "\n",
    "def shuffle(inFile):\n",
    "    '''\n",
    "        简单的乱序操作，用于生成训练集和测试集\n",
    "    '''\n",
    "    textLines = [line.strip() for line in open(inFile)]\n",
    "    print \"正在准备训练和测试数据，请稍后...\"\n",
    "    random.shuffle(textLines)\n",
    "    num = len(textLines)\n",
    "    trainText = textLines[:3*num/5]\n",
    "    testText = textLines[3*num/5:]\n",
    "    print \"准备训练和测试数据准备完毕，下一步...\"\n",
    "    return trainText, testText\n",
    "\n",
    "#总共有9种新闻类别，我们给每个类别一个编号\n",
    "lables = ['A','B','C','D','E','F','G','H','I']\n",
    "def lable2id(lable):\n",
    "    for i in xrange(len(lables)):\n",
    "        if lable == lables[i]:\n",
    "            return i\n",
    "    raise Exception('Error lable %s' % (lable))\n",
    "\n",
    "def doc_dict():\n",
    "    '''\n",
    "        构造和类别数等长的0向量\n",
    "    '''\n",
    "    return [0]*len(lables)\n",
    "\n",
    "def mutual_info(N,Nij,Ni_,N_j):\n",
    "    '''\n",
    "        计算互信息，这里log的底取为2\n",
    "    '''\n",
    "    return Nij * 1.0 / N * math.log(N * (Nij+1)*1.0/(Ni_*N_j))/ math.log(2)\n",
    "    \n",
    "def count_for_cates(trainText, featureFile):\n",
    "    '''\n",
    "        遍历文件，统计每个词在每个类别出现的次数，和每类的文档数\n",
    "        并写入结果特征文件\n",
    "    '''\n",
    "    docCount = [0] * len(lables)\n",
    "    wordCount = collections.defaultdict(doc_dict())\n",
    "    #扫描文件和计数  \n",
    "    for line in trainText:\n",
    "        lable,text = line.strip().split(' ',1)\n",
    "        index = lable2id(lable[0])        \n",
    "        words = text.split(' ')\n",
    "        for word in words:\n",
    "            wordCount[word][index] += 1\n",
    "            docCount[index] += 1\n",
    "    #计算互信息值\n",
    "    print \"计算互信息，提取关键/特征词中，请稍后...\"\n",
    "    miDict = collections.defaultdict(doc_dict())\n",
    "    N = sum(docCount)\n",
    "    for k,vs in wordCount.items():\n",
    "        for i in xrange(len(vs)):\n",
    "            N11 = vs[i]\n",
    "            N10 = sum(vs) - N11\n",
    "            N01 = docCount[i] - N11\n",
    "            N00 = N - N11 - N10 - N01\n",
    "            mi = mutual_info(N,N11,N10+N11,N01+N11) + mutual_info(N,N10,N10+N11,N00+N10)+ mutual_info(N,N01,N01+N11,N01+N00)+ mutual_info(N,N00,N00+N10,N00+N01)\n",
    "            miDict[k][i] = mi\n",
    "    fWords = set()\n",
    "    for i in xrange(len(docCount)):\n",
    "        keyf = lambda x:x[1][i]\n",
    "        sortedDict = sorted(miDict.items(),key=keyf,reverse=True)\n",
    "        for j in xrange(100):\n",
    "            fWords.add(sortedDict[j][0])\n",
    "    out = open(featureFile, 'w')\n",
    "    #输出各个类的文档数目\n",
    "    out.write(str(docCount)+\"\\n\")\n",
    "    #输出互信息最高的词作为特征词\n",
    "    for fword in fWords:\n",
    "        out.write(fword+\"\\n\")\n",
    "    print \"特征词写入完毕...\"\n",
    "    out.close()\n",
    "    \n",
    "def load_feature_words(featureFile):\n",
    "    '''\n",
    "        从特征文件导入特征词\n",
    "    '''\n",
    "    f = open(featureFile)\n",
    "    #各个类的文档数目\n",
    "    docCounts = eval(f.readline())\n",
    "    features = set()\n",
    "    #读取特征词\n",
    "    for line in f:\n",
    "        features.add(line.strip())\n",
    "    f.close()\n",
    "    return docCounts,features\n",
    "            \n",
    "def train_bayes(featureFile, textFile, modelFile):\n",
    "    '''\n",
    "        训练贝叶斯模型，实际上计算每个类中特征词的出现次数\n",
    "    '''\n",
    "    print \"使用朴素贝叶斯训练中...\"\n",
    "    docCounts,features = load_feature_words(featureFile)\n",
    "    wordCount = collections.defaultdict(doc_dict())\n",
    "    #每类文档特征词出现的次数\n",
    "    tCount = [0]*len(docCounts)\n",
    "    for line in open(textFile):\n",
    "        lable,text = line.strip().split(' ',1)\n",
    "        index = lable2id(lable[0])        \n",
    "        words = text.split(' ')\n",
    "        for word in words:\n",
    "            if word in features:\n",
    "                tCount[index] += 1\n",
    "                wordCount[word][index] += 1\n",
    "    outModel = open(modelFile, 'w')\n",
    "    #拉普拉斯平滑\n",
    "    print \"训练完毕，写入模型...\"\n",
    "    for k,v in wordCount.items():\n",
    "        scores = [(v[i]+1) * 1.0 / (tCount[i]+len(wordCount)) for i in xrange(len(v))]\n",
    "        outModel.write(k+\"\\t\"+scores+\"\\n\")\n",
    "    outModel.close()\n",
    "        \n",
    "def load_model(modelFile):\n",
    "    '''\n",
    "        从模型文件中导入计算好的贝叶斯模型\n",
    "    '''\n",
    "    print \"加载模型中...\"\n",
    "    f = open(modelFile)\n",
    "    scores = {}\n",
    "    for line in f:\n",
    "        word,counts = line.strip().rsplit('\\t',1)    \n",
    "        scores[word] = eval(counts)\n",
    "    f.close()\n",
    "    return scores\n",
    "    \n",
    "def predict(featureFile, modelFile, testText):\n",
    "    '''\n",
    "        预测文档的类标，标准输入每一行为一个文档\n",
    "    '''\n",
    "    docCounts,features = load_feature_words()    \n",
    "    docScores = [math.log(count * 1.0 /sum(docCounts)) for count in docCounts]\n",
    "    scores = load_model(modelFile)\n",
    "    rCount = 0\n",
    "    docCount = 0\n",
    "    print \"正在使用测试数据验证模型效果...\"\n",
    "    for line in testText:\n",
    "        lable,text = line.strip().split(' ',1)\n",
    "        index = lable2id(lable[0])        \n",
    "        words = text.split(' ')\n",
    "        preValues = list(docScores)\n",
    "        for word in words:\n",
    "            if word in features:                \n",
    "                for i in xrange(len(preValues)):\n",
    "                    preValues[i]+=math.log(scores[word][i])\n",
    "        m = max(preValues)\n",
    "        pIndex = preValues.index(m)\n",
    "        if pIndex == index:\n",
    "            rCount += 1\n",
    "        #print lable,lables[pIndex],text\n",
    "        docCount += 1\n",
    "    print(\"总共测试文本量: %d , 预测正确的类别量: %d, 朴素贝叶斯分类器准确度:%f\" %(rCount,docCount,rCount * 1.0 / docCount))       \n",
    "        \n",
    "        \n",
    "if __name__==\"__main__\":\n",
    "    if len(sys.argv) != 4:\n",
    "    print \"Usage: python sohu_news_topic_classification_using_naive_bayes.py sougou_news.txt feature_file.out model_file.out\"\n",
    "    sys.exit()\n",
    "\n",
    "    inFile = sys.argv[1]\n",
    "    featureFile = sys.argv[2]\n",
    "    modelFile = sys.argv[3]\n",
    "\n",
    "    trainText, testText = shuffle(inFile)\n",
    "    count_for_cates(trainText, featureFile)\n",
    "    train_bayes(featureFile, trainText, modelFile)\n",
    "    predict(featureFile, modelFile, testText)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
